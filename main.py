import os
import mysql.connector
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_ollama import OllamaLLM as Ollama
from langchain.prompts import PromptTemplate
from langchain_core.documents import Document

DATA_PATH = "data.txt"
DB_DIR = "db"
SIMILARITY_THRESHOLD = 0.8

# Load components at startup
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
llm = Ollama(model="llama3.2")
# llm = Ollama(model="llama3.2:1b", max_tokens=200, temperature=0.0)

if os.path.exists(DB_DIR):
    db = Chroma(persist_directory=DB_DIR, embedding_function=embedding_model)
else:
    loader = TextLoader(DATA_PATH, encoding='utf-8')
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # 500 50
    docs = text_splitter.split_documents(documents)
    db = Chroma.from_documents(docs, embedding_model, persist_directory=DB_DIR)

retriever = db.as_retriever(search_kwargs={"k": 2})

prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
        {context}

        C√¢u h·ªèi: {question}
        """
)
def fetch_new_tours_from_mysql():
    conn = mysql.connector.connect(
        host="localhost", user="root", password="", database="travela"
    )
    cursor = conn.cursor(dictionary=True)
    cursor.execute("""
        SELECT tourId, title, time, quantity, priceAdult, priceChild, duration, 
               destination, availability, description, reviews, domain, startDate, endDate
        FROM tbl_tours 
        WHERE startDate >= NOW() - INTERVAL 5 MINUTE
    """)
    rows = cursor.fetchall()
    conn.close()
    return rows

def update_vector_db_from_mysql():
    new_tours = fetch_new_tours_from_mysql()
    if not new_tours:
        return
    docs = []
    for tour in new_tours:
        content = (
            f"Ti√™u ƒë·ªÅ: {tour['title']}\n"
            f"Th·ªùi gian: {tour['time']}\n"
            f"S·ªë l∆∞·ª£ng: {tour['quantity']}\n"
            f"Gi√° ng∆∞·ªùi l·ªõn: {tour['priceAdult']} VND\n"
            f"Gi√° tr·∫ª em: {tour['priceChild']} VND\n"
            f"Th·ªùi l∆∞·ª£ng: {tour['duration']}\n"
            f"ƒêi·ªÉm ƒë·∫øn: {tour['destination']}\n"
            f"Tr·∫°ng th√°i: {'C√≤n ch·ªó' if tour['availability'] else 'H·∫øt ch·ªó'}\n"
            f"M√¥ t·∫£: {tour['description']}\n"
            f"ƒê√°nh gi√°: {tour['reviews']}\n"
            f"Mi·ªÅn: {'Mi·ªÅn B·∫Øc' if tour['domain']=='b' else 'Mi·ªÅn Trung' if tour['domain']=='t' else 'Mi·ªÅn Nam'}\n"
            f"Kh·ªüi h√†nh: {tour['startDate']}\n"
            f"K·∫øt th√∫c: {tour['endDate']}"
        )
        docs.append(Document(page_content=content, metadata={"tourId": tour["tourId"]}))
    db.add_documents(docs)
    print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t {len(docs)} tour m·ªõi v√†o VectorDB.")


# while True:
#     query = input("B·∫°n: ")
#     if query.lower() == "exit":
#         break

#     relevant_docs = db.similarity_search_with_score(query, k=3)

#     print("üìä M·ª©c ƒë·ªô t∆∞∆°ng ƒë·ªìng:")
#     for doc, score in relevant_docs:
#         print(f"Score: {score:.4f} ‚Üí {'D√πng' if score <= SIMILARITY_THRESHOLD else 'B·ªè'}")

#     filtered_docs = [doc for doc, score in relevant_docs if score <= SIMILARITY_THRESHOLD]

#     if filtered_docs:
#         context = "\n".join([doc.page_content for doc in filtered_docs])
#         formatted_prompt = prompt_template.format(context=context, question=query)
#         response = llm.invoke(formatted_prompt)
#         print(f"\nBot (t·ª´ d·ªØ li·ªáu): {response}")
#     else:
#         pretrain_response = llm.invoke(query)
#         print(f"Bot (pretrain): {pretrain_response}")

#     print("\n")
